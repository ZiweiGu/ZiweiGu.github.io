<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-11-07T22:44:19+08:00</updated><id>http://localhost:4000/feed.xml</id><entry><title type="html">What I Learned from Doing Research</title><link href="http://localhost:4000/2021/11/05/what-i-learned.html" rel="alternate" type="text/html" title="What I Learned from Doing Research" /><published>2021-11-05T00:00:00+08:00</published><updated>2021-11-05T00:00:00+08:00</updated><id>http://localhost:4000/2021/11/05/what-i-learned</id><content type="html" xml:base="http://localhost:4000/2021/11/05/what-i-learned.html">&lt;p&gt;I loved every bit of my 2+ years of research experience at Cornell. I was also grateful for the opportunity to participate in top conferences like WWW’21, CHI’20, and CHI’21. Overall, the experiences are life-changing, and I’d like to summarize some of my learnings here (constantly updating) as a reference to others and to myself.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Research Project Management&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;When a project involves significant system building, it’s a great idea to spend enough time &lt;strong&gt;designing and brainstorming&lt;/strong&gt; before implementing. It’s tempting to start coding early and deliver a prototype quickly so that you can cheerfully declare “we are almost done!” However, it’s highly risky as it often leaves you in a dangerous situation where things don’t work as expected and you are stuck with hours and hours of wasted work. Plan well and only start implementing when the team has a clear vision of the system.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;“Start simple, fail fast, fail early.”&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;HCI is centered on humans. &lt;strong&gt;Put users’ need first!&lt;/strong&gt; It’s easier said than done because we developers tend to get lost in what we can do, what’s new, and what’s cool. For example, when displaying data, we must resist the temptation to show everything we have computed so that users don’t have to suffer from information overload. One method I like to use is to stand in users’ shoes and ask what they’re gonna do with all those information.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Pick impactful research ideas&lt;/strong&gt; worthy of your pursuit (e.g those that have a potential to fundamentally change some previous beliefs, to influence a large number of people, to inspire a new class of systems, etc.). “It’s as easy to do something big as it is to do something small.”&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A procedure I found effective to start and complete a research project (after having a rough research idea in mind):&lt;/p&gt;
    &lt;ol&gt;
      &lt;li&gt;&lt;strong&gt;Have a mental model&lt;/strong&gt; of what a successful project looks like. (Yes, this is the first step!)&lt;/li&gt;
      &lt;li&gt;Do a lot of literature review and write a &lt;strong&gt;research proposal&lt;/strong&gt;.&lt;/li&gt;
      &lt;li&gt;Have your advisor read the proposal and have an &lt;strong&gt;open and objective&lt;/strong&gt; discussion with them.&lt;/li&gt;
      &lt;li&gt;(If both of you are passionate) Start carving out the general framework in Overleaf. (&lt;strong&gt;Writing&lt;/strong&gt; is a great way to get you started and help organize thought.)&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Make plans&lt;/strong&gt; on tasks. To-do list, timelines, milestones. &lt;strong&gt;Prioritize&lt;/strong&gt;!&lt;/li&gt;
      &lt;li&gt;Design and Implementat. Code, test, iterate.&lt;/li&gt;
      &lt;li&gt;Fill out the empty sections in Overleaf from Step 4 and finish writing.&lt;/li&gt;
      &lt;li&gt;After submission, &lt;strong&gt;reflect&lt;/strong&gt; on the whole process and &lt;strong&gt;take notes&lt;/strong&gt; of any thought or feedback.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Communication&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Be bold&lt;/strong&gt;. If there’s someone you admire, email them to ask for advice or a meeting. You never know who will be willing to meet with you. If there’s an opportunity you are excited about, take immediate actions to get closer to it. You never know what you can take home. I used to be shy about reaching out, but by forcing myself out of my comfort zone, I have met and talked to board members of Cornell, CXO of Lyft, chairs of CHI, learned important life lessions and formed long-term connections.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A tip on reaching out to people: people are always more interested in &lt;strong&gt;their own problems&lt;/strong&gt; than your problems. So if you want to reach someone, start with what they are dealing with. A practical example: email a professor by starting with &lt;em&gt;their&lt;/em&gt; research, not yours.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;I found it crucial to &lt;strong&gt;be candid&lt;/strong&gt; when discussing research ideas and each other’s work. I used to be leery of saying anything negative about others’ or our collaborative work. After witnessing the power of a group of smart people talking openly with one another in a CHI session, however, I realized they could overcome any obstacles this way. Now I talk about failures openly and objectively. (But be sure to be friendly and inclusive!)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;When presenting your research, &lt;strong&gt;sell the problem&lt;/strong&gt; you are solving, and &lt;strong&gt;accent the difference&lt;/strong&gt; your are making! &lt;strong&gt;Be concise!&lt;/strong&gt; Skip any part that is not adding value to your message. Be very careful when adding long sentences to your slides: the only texts on slides should be the “take-home” messages you want your audience to remember.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Motivation and Productivity&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;I felt somewhat complacent for a while after landing an internship offer from Lyft, and I deeply regretted it. It turned out that &lt;strong&gt;nothing is forever&lt;/strong&gt;. Our goals and expectations are constantly changing, so we need to constantly seek ways to improve or even reinvent ourselves.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Worthy pursuits require &lt;strong&gt;100% effort&lt;/strong&gt;. If there’s a contest (or anything competitive), and you are not 100% certain whether to participate, then you’d better not participate. While you are not going to all in it, your competitors are, many of whom are set to devote everything they have to it. Thus, you are already out of the game unless you can beat them from a higher dimension.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Work is hard, but &lt;strong&gt;“inspired actions”&lt;/strong&gt; are not. My friends often ask me how I manage to work long period without being burned out. To be honest, I don’t think I’m “working”, instead I’m trying to take “inspired actions” every day. Truly inspired actions are effortless.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Be grateful&lt;/strong&gt; every day and let others know your gratitude.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Ziwei Gu</name></author><category term="Reflection" /><summary type="html">I loved every bit of my 2+ years of research experience at Cornell. I was also grateful for the opportunity to participate in top conferences like WWW’21, CHI’20, and CHI’21. Overall, the experiences are life-changing, and I’d like to summarize some of my learnings here (constantly updating) as a reference to others and to myself.</summary></entry><entry><title type="html">Why Eigenvalues Are So Important</title><link href="http://localhost:4000/2019/08/19/why-eigenvalues.html" rel="alternate" type="text/html" title="Why Eigenvalues Are So Important" /><published>2019-08-19T00:00:00+08:00</published><updated>2019-08-19T00:00:00+08:00</updated><id>http://localhost:4000/2019/08/19/why-eigenvalues</id><content type="html" xml:base="http://localhost:4000/2019/08/19/why-eigenvalues.html">&lt;p&gt;Okay, let’s bring out the question most professors would not bother to explain: why do we care so much about vectors that become a multiple of themselves when you multiply by a matrix?&lt;/p&gt;

&lt;p&gt;Short (and very shallow) answer: Applications.&lt;/p&gt;

&lt;p&gt;Eigenvalues are essential in physical applications like rotations, image compression, and quantum mechanics, and numerous data science applications (PCA, markov chains, latent variable models, and much more…) They are not only used to explain natural occurrences, but also to discover new and better designs for the future.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A longer and deeper answer&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;“A central goal of linear algebra is to show that given an operator T ∈ L(V), there exists a basis of V with respect to which T has a reasonably simple matrix” (e.g. with many 0’s - diagonal matrix). Diagonal matrices are nice because it’s easier to take powers, decompose, visualize, etc.&lt;/p&gt;

&lt;p&gt;Furthermore, eigenvalues offer you the power to distinguish among representations. A matrix is simply one way of representing a linear transformation in a particular basis you chose, but the matrix changes when you change the basis. Eigenvalues, on the other hand, are invariant under change of basis. Therefore, they are much more fundamental. They characterize the intrinsic properties about a linear transformation. Math, in some sense, is to find those things intrinsic to the universe. It’s therefore not surprising that eigenvalues are everywhere.&lt;/p&gt;</content><author><name>Ziwei Gu</name></author><category term="Linear Algebra" /><summary type="html">Okay, let’s bring out the question most professors would not bother to explain: why do we care so much about vectors that become a multiple of themselves when you multiply by a matrix?</summary></entry><entry><title type="html">Facts about Eigenvalues</title><link href="http://localhost:4000/2019/08/18/facts-about-eigenvalues.html" rel="alternate" type="text/html" title="Facts about Eigenvalues" /><published>2019-08-18T00:00:00+08:00</published><updated>2019-08-18T00:00:00+08:00</updated><id>http://localhost:4000/2019/08/18/facts-about-eigenvalues</id><content type="html" xml:base="http://localhost:4000/2019/08/18/facts-about-eigenvalues.html">&lt;p&gt;First, some clarifications. We are considering linear maps from a finite-dimensional vector space to itself (also called an &lt;strong&gt;operator&lt;/strong&gt; L(V)), as opposed to linear maps from one vector space to another vector space.&lt;/p&gt;

&lt;p&gt;Suppose &lt;em&gt;V&lt;/em&gt; is a finite-dimensional vector space, &lt;em&gt;T&lt;/em&gt; ∈ &lt;em&gt;L&lt;/em&gt;(&lt;em&gt;V&lt;/em&gt;), and λ ∈ &lt;em&gt;F&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Some definitions to know:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Invariant subspace: U is invariant under T if T|&lt;sub&gt;U&lt;/sub&gt; is an operator on U.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;λ ∈ &lt;em&gt;F&lt;/em&gt;  is an eigenvalue of T if ∃ v ∈ V s.t. v ≠ 0 and Tv = λv.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The eigenspace of T corresponding to λ, E(λ, T) = null(T - λI) (the set of all eigenvectors of T corresponding to λ, along with the 0 vector.)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Concepts from &lt;a href=&quot;/2019/08/17/jectivity.html&quot;&gt;a previous post&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Basics&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;A linear map is invertible if and only if it is injective and surjective.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;For operators on a finite-dimensional vector space, however, either injectivity or surjectivity alone implies the other condition, and thus implies invertibility. (proved using Rank theorem)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If λ is an eigenvalue of T, then by definition v ∈ ker(T - λI) so ker(T - λI) ≠ 0. Hence, T - λI is not injective (or surjective). That is, T - λI is not invertible, det(T - λI) = 0.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Eigenvectors corresponding to &lt;strong&gt;distinct&lt;/strong&gt; eigenvalues are linearly independent.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Each operator on V has at most dim V distinct eigenvalues.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If A is an n ×n matrix, then the sum of the n eigenvalues of A is the trace of A and the
product of the n eigenvalues is the determinant of A.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If λ is an eigenvalue of the T, λ&lt;sup&gt;2&lt;/sup&gt; is an eigenvalue of T&lt;sup&gt;2&lt;/sup&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;n × n matrix A and its transpose A&lt;sup&gt;T&lt;/sup&gt; have the same eigenvalues.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Suppose A and B are similar matrices. Then A and B have the same characteristic polynomial and
hence the same eigenvalue.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If λ is an eigenvalue of A, then the dimension of E&lt;sub&gt;λ&lt;/sub&gt; is at most the multiplicity of λ.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If λ&lt;sup&gt;*&lt;/sup&gt; is an eigenvalue of A, then the multiplicity of λ&lt;sup&gt;*&lt;/sup&gt; is at least the dimension of the eigenspace E&lt;sub&gt;λ&lt;sup&gt;*&lt;/sup&gt;&lt;/sub&gt; .&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Intermediate&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Any two polynomials of an operator commute.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Every operator on a finite-dimensional, nonzero, complex vector space has an eigenvalue.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Over C, every operator has an upper-triangular matrix&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Suppose T ∈ L(V) has an upper-triangular matrix with respect to some basis of V, then T is invertible if and only if all the entries on the diagonal of that upper-triangular matrix are nonzero;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Suppose T ∈ L(V) has an upper-triangular matrix with respect to some basis of V, then the eigenvalues of T are precisely the entries on the diagonal of that upper-triangular matrix.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Let λ&lt;sub&gt;1&lt;/sub&gt;, …, λ&lt;sub&gt;m&lt;/sub&gt; denote the distinct eigenvalues of T. Then, T is diagonalizable&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;         &amp;lt;=&amp;gt; V has a basis consisting of eigenvectors of T&lt;/p&gt;

&lt;p&gt;         &amp;lt;=&amp;gt; ∃ 1-dimensional subspaces U&lt;sub&gt;1&lt;/sub&gt;, …, U&lt;sub&gt;n&lt;/sub&gt; of V, each invariant under T, such that V          = U&lt;sub&gt;1&lt;/sub&gt; ⊕ … ⊕ U&lt;sub&gt;n&lt;/sub&gt;&lt;/p&gt;

&lt;p&gt;         &amp;lt;=&amp;gt; V = E(λ&lt;sub&gt;1&lt;/sub&gt;, T) ⊕ … ⊕ E(λ&lt;sub&gt;m&lt;/sub&gt;, T)&lt;/p&gt;

&lt;p&gt;         &amp;lt;=&amp;gt; dim V = dim E(λ&lt;sub&gt;1&lt;/sub&gt;, T) + … + dim E(λ&lt;sub&gt;m&lt;/sub&gt;, T)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;If T has dim V (enough) distinct eigenvalues, then T is diagonalizable. (The converse is not true, as the diagonalizable identity operator only has only 1 eigenvalue λ = 1)&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Ziwei Gu</name></author><category term="Linear Algebra" /><summary type="html">First, some clarifications. We are considering linear maps from a finite-dimensional vector space to itself (also called an operator L(V)), as opposed to linear maps from one vector space to another vector space.</summary></entry><entry><title type="html">Master “-jectivity”</title><link href="http://localhost:4000/2019/08/17/jectivity.html" rel="alternate" type="text/html" title="Master “-jectivity”" /><published>2019-08-17T00:00:00+08:00</published><updated>2019-08-17T00:00:00+08:00</updated><id>http://localhost:4000/2019/08/17/jectivity</id><content type="html" xml:base="http://localhost:4000/2019/08/17/jectivity.html">&lt;p&gt;Definitions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;null space&lt;/strong&gt; of T: null T = {v ∈ V: Tv = 0} (stuff in the original vector space that’s mapped to 0 by T)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;range&lt;/strong&gt; of T: range T = {Tv: v ∈ V} (all the resulting vectors after the mapping T)&lt;/li&gt;
  &lt;li&gt;A function T: V -&amp;gt; W is &lt;strong&gt;injective&lt;/strong&gt; if Tu = Tv implies u = v.&lt;/li&gt;
  &lt;li&gt;A function T: V -&amp;gt; W is &lt;strong&gt;surjective&lt;/strong&gt; if its range equals W.&lt;/li&gt;
  &lt;li&gt;An &lt;strong&gt;isomorphism&lt;/strong&gt; is an invertible (injective + surjective) linear map.&lt;/li&gt;
  &lt;li&gt;Two vector spaces are isomorphic if there is an isomorphism from one vector space onto the other one.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Facts:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;A linear map is injective iff null T = {0}.
&lt;span style=&quot;color:gray&quot;&gt;[Proof Idea: if v ∈ null T then T(v) = 0 = T(0) =&amp;gt; v = 0 so null T ⊆ {0}; other direction trivial.]&lt;/span&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Rank-Nullity: if T ∈ L(V, W) then dim V = dim null T + dim range T&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A map to a smaller dimensional space is not injective. (“smaller” as measured by &lt;em&gt;dimension&lt;/em&gt;)
&lt;span style=&quot;color:gray&quot;&gt;[Proof Idea: using Rank-Nullity]&lt;/span&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A map to a larger dimensional space is not surjective.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If T is invertible, it’s inverse is unique.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Two finite-dimensional vector spaces over F are isomorphic if and only if they have the same dimension. 
&lt;span style=&quot;color:gray&quot;&gt;[Proof Idea: consider T: V -&amp;gt; W; =&amp;gt;: using Rank-Nullity; &amp;lt;=: denote basis of V, W. Apply T to the linear combination of the basis of V, which results in the same linear combination of the basis of W, we can show T is surjective and injective, and is thus invertible.]&lt;/span&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;L(V, W) and F&lt;sup&gt;m,n&lt;/sup&gt; are isomorphic&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;dim F&lt;sup&gt;m,n&lt;/sup&gt; = mn 
&lt;span style=&quot;color:gray&quot;&gt;[Proof Idea: m-by-n matrices that have 0 in all entries except for a 1 in one entry form a basis of F&lt;sup&gt;m,n&lt;/sup&gt;. How many of them are there?]&lt;/span&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Based on the previous two facts, dim L(V, W) = (dim V)(dim W)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Ziwei Gu</name></author><category term="Linear Algebra" /><summary type="html">Definitions:</summary></entry></feed>